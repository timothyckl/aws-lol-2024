{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58a205eb-50f4-45cd-9eff-cf2c16b9dbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 88 seed instructions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "prompt_batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [01:54<00:00,  3.95s/it]\n",
      " 18%|████████████████████▏                                                                                           | 18/100 [02:19<01:55,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request 1 took 114.59s, processing took 25.40s\n",
      "Generated 32 instructions, kept 18 instructions\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "prompt_batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [03:57<00:00,  8.20s/it]\n",
      " 30%|█████████████████████████████████▌                                                                              | 30/100 [06:36<03:38,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request 2 took 237.66s, processing took 25.29s\n",
      "Generated 32 instructions, kept 12 instructions\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "prompt_batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [01:55<00:00,  3.98s/it]\n",
      " 38%|██████████████████████████████████████████▌                                                                     | 38/100 [08:58<07:11,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request 3 took 115.31s, processing took 24.54s\n",
      "Generated 31 instructions, kept 8 instructions\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "prompt_batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [01:42<00:00,  3.52s/it]\n",
      " 47%|████████████████████████████████████████████████████▋                                                           | 47/100 [11:06<04:16,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request 4 took 102.02s, processing took 25.20s\n",
      "Generated 32 instructions, kept 9 instructions\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "prompt_batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [01:37<00:00,  3.36s/it]\n",
      " 52%|██████████████████████████████████████████████████████████▏                                                     | 52/100 [13:06<08:25, 10.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request 5 took 97.37s, processing took 24.19s\n",
      "Generated 31 instructions, kept 5 instructions\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "prompt_batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [01:40<00:00,  3.46s/it]\n",
      " 56%|██████████████████████████████████████████████████████████████▋                                                 | 56/100 [15:13<13:18, 18.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request 6 took 100.43s, processing took 26.64s\n",
      "Generated 33 instructions, kept 4 instructions\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "prompt_batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [01:45<00:00,  3.65s/it]\n",
      " 60%|███████████████████████████████████████████████████████████████████▏                                            | 60/100 [17:23<13:11, 19.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request 7 took 105.87s, processing took 26.04s\n",
      "Generated 34 instructions, kept 4 instructions\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "prompt_batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [02:14<00:00,  4.65s/it]\n",
      " 68%|████████████████████████████████████████████████████████████████████████████▏                                   | 68/100 [20:09<03:44,  7.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request 8 took 134.82s, processing took 27.93s\n",
      "Generated 35 instructions, kept 8 instructions\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "prompt_batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [01:53<00:00,  3.92s/it]\n",
      " 73%|█████████████████████████████████████████████████████████████████████████████████▊                              | 73/100 [22:29<06:08, 13.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request 9 took 113.66s, processing took 25.84s\n",
      "Generated 33 instructions, kept 5 instructions\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "prompt_batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [01:49<00:00,  3.77s/it]\n",
      " 83%|████████████████████████████████████████████████████████████████████████████████████████████▉                   | 83/100 [24:48<01:07,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request 10 took 109.21s, processing took 26.69s\n",
      "Generated 34 instructions, kept 10 instructions\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "prompt_batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [01:42<00:00,  3.53s/it]\n",
      " 89%|███████████████████████████████████████████████████████████████████████████████████████████████████▋            | 89/100 [26:52<01:42,  9.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request 11 took 102.23s, processing took 25.16s\n",
      "Generated 31 instructions, kept 6 instructions\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "prompt_batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [01:55<00:00,  3.97s/it]\n",
      " 95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▍     | 95/100 [29:08<00:47,  9.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request 12 took 115.13s, processing took 28.43s\n",
      "Generated 36 instructions, kept 6 instructions\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "prompt_batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [02:03<00:00,  4.26s/it]\n",
      "101it [31:50, 18.92s/it]                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request 13 took 123.62s, processing took 27.21s\n",
      "Generated 34 instructions, kept 6 instructions\n",
      "\n",
      "\n",
      "Generation complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from module import SelfInstruct\n",
    "\n",
    "self_instruct = SelfInstruct(\n",
    "    api_key=\"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\",\n",
    "    model_provider=\"openai\",\n",
    "    model_name=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt_template_path=\"../scripts/self-instruct/prompt.txt\",\n",
    "    seed_tasks_path=\"../scripts/self-instruct/sample-seed-tasks/0-seed-tasks-deduped-finished.jsonl\",\n",
    "    num_instructions_to_generate=100,  # total number of instructions to generate\n",
    "    num_prompt_instructions=3,  # number of seed tasks to sample from\n",
    "    request_batch_size=29,  # number of requests in a batch\n",
    "    num_cpus=8,\n",
    ")\n",
    "\n",
    "self_instruct.configure_prompt(\n",
    "    topic='Machine Learning', \n",
    "    difficulty='Advanced'\n",
    ")\n",
    "\n",
    "self_instruct.generate(output_dir=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bb675a-20a8-4ec9-bd1b-f96a6802c947",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
