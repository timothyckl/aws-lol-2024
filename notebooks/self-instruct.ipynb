{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f549b54-40f7-466b-8531-960ac8a41c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.mistralai import MistralAI\n",
    "from llama_index.embeddings.mistralai import MistralAIEmbedding\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "env = dotenv_values(\"../.env\")\n",
    "\n",
    "llm = MistralAI(\n",
    "    api_key=env['MISTRAL_API_KEY'],\n",
    "    model=\"mistral-medium\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=1024,\n",
    "    timeout=120,\n",
    "    max_retries=5,\n",
    "    safe_mode=False,\n",
    "    random_seed=None,\n",
    ")\n",
    "\n",
    "# embed_model = MistralAIEmbedding(model_name='mistral-embed', api_key=MISTRAL_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0715f21c-1bbe-4d92-bc04-58d0354a235e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction:\n",
      "I am preparing a set of exam questions about machine learning theory. \n",
      "Generate 50 questions on machine learning theory for me in this jsonl format: \n",
      "{\"instruction\": <Insert exam question>,\"context\":\"\",\"response\":\"<insert response here>} \n",
      "Each json should be begin at a brand new line.\n",
      "\n",
      "Questions:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topic = \"machine learning theory\"\n",
    "num_questions = 50\n",
    "\n",
    "prompt = f'''\\\n",
    "Instruction:\n",
    "I am preparing a set of exam questions about {topic}. \\\n",
    "\n",
    "Generate {num_questions} questions on {topic} for me in this jsonl format: \\\n",
    "\n",
    "{{\"instruction\": <Insert exam question>,\"context\":\"\",\"response\":\"<insert response here>}} \\\n",
    "\n",
    "Each json should be begin at a brand new line.\n",
    "\n",
    "Questions:\n",
    "'''\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58a205eb-50f4-45cd-9eff-cf2c16b9dbbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I help you today? Is there something you would like to talk about or ask me? I'm here to help answer any questions you might have to the best of my ability. I can provide information on a wide range of topics, including science, history, technology, culture, and more. I can also help with tasks such as generating ideas, solving problems, and providing explanations. Let me know how I can assist you.\n"
     ]
    }
   ],
   "source": [
    "resp = llm.complete(prompt)\n",
    "print(resp.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
