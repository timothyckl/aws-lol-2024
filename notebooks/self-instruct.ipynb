{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f549b54-40f7-466b-8531-960ac8a41c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from module import SelfInstruct\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58a205eb-50f4-45cd-9eff-cf2c16b9dbbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 17:02:08,791 DEBUG httpx: load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2024-02-26 17:02:08,794 DEBUG httpx: load_verify_locations cafile='/home/tim/miniconda3/envs/aws-lol-env/lib/python3.11/site-packages/certifi/cacert.pem'\n"
     ]
    }
   ],
   "source": [
    "self_instruct = SelfInstruct(\n",
    "    api_key=\"asdasdasd\",\n",
    "    model_provider=\"openai\",\n",
    "    model_name=\"text-davinci-003\",\n",
    "    prompt_template_path=\"../scripts/self-instruct/prompt.txt\",\n",
    "    seed_tasks_path=\"../scripts/self-instruct/seed_tasks.jsonl\",\n",
    "    num_instructions_to_generate=100,\n",
    "    num_prompt_instructions=3,\n",
    ")\n",
    "\n",
    "self_instruct.configure_prompt(\n",
    "    topic='Machine Learning', \n",
    "    difficulty='Beginner'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "449eee17-c36c-4546-9a87-f9345fea0355",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 17:02:11,338 INFO absl: Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20 human-written seed instructions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                 | 0/100 [00:00<?, ?it/s]\n",
      "prompt_batches:   0%|                                                                                                                                   | 0/5 [00:00<?, ?it/s]\u001b[A2024-02-26 17:02:11,345 DEBUG openai._base_client: Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ['You are asked to come up with a set of 100 exam questions on diverse topics related to Machine Learning at Beginner level. These question sets will be given to an language model and we will evaluate the language model for completing the instructions.\\n\\nHere are the requirements:\\n1. Try not to repeat the verb for each question to maximize diversity.\\n2. The language used for the questions also should be diverse. For example, you should combine questions with imperative instructions.\\n3. The topics in these questions should be diverse. The list should include diverse types of questions like open-ended generation, multiple-choice, true/false etc.\\n2. A language model should be able to complete the instruction. For example, do not ask the assistant to create any visual or audio output. For another example, do not ask the assistant to wake you up at 5pm or set a reminder because it cannot perform any action.\\n3. The questions should be in English.\\n4. The questions should be 1 to 2 sentences long. Either an imperative sentence or a question is permitted.\\n5. You should generate an appropriate topic related to the question. The topic should provide substantial content to make the question challenging but should ideally not exceed 100 words.\\n6. The output should be an appropriate response to the question and information provided. Make sure the output is less than 100 words.\\n7. Questions should be in the following jsonl format: {\"id\": \"seed_task_<insert number here>\", \"instruction\": \"<insert question here>\", \"info\": [{\"difficulty\": \"<insert difficulty here>\", \"topic\": \"<insert topic name here>\"}], \"output\": \"<insert response here>\"}. Each question should begin at a brand new line.\\n\\nList of 100 questions:\\n\\n\\n\\n###\\n1. Instruction: Explain the concept of underfitting in machine learning models.\\n1. Output: Underfitting occurs when a model is too simple to capture the underlying patterns in the data, resulting in poor performance both on the training and test datasets.\\n###\\n2. Instruction: Explain the concept of batch gradient descent in optimizing a neural network.\\n2. Output: Batch gradient descent computes the gradient of the loss function using the entire training dataset in each iteration, updating the model parameters accordingly to minimize the loss.\\n###\\n3. Instruction: What is the role of a loss function in training a machine learning model?\\n3. Output: The loss function quantifies the model\\'s prediction error during training, guiding the optimization process towards finding the optimal model parameters.\\n###\\n4. Instruction:'], 'max_tokens': 3072, 'n': 1, 'temperature': 0.7, 'top_p': 1.0}}\n",
      "2024-02-26 17:02:11,350 DEBUG httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-02-26 17:02:11,514 DEBUG httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f68c97deb10>\n",
      "2024-02-26 17:02:11,516 DEBUG httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x7f690a3ad130> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-02-26 17:02:11,606 DEBUG httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f68c97d81d0>\n",
      "2024-02-26 17:02:11,607 DEBUG httpcore.http11: send_request_headers.started request=<Request [b'POST']>\n",
      "2024-02-26 17:02:11,610 DEBUG httpcore.http11: send_request_headers.complete\n",
      "2024-02-26 17:02:11,611 DEBUG httpcore.http11: send_request_body.started request=<Request [b'POST']>\n",
      "2024-02-26 17:02:11,612 DEBUG httpcore.http11: send_request_body.complete\n",
      "2024-02-26 17:02:11,612 DEBUG httpcore.http11: receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-02-26 17:02:12,019 DEBUG httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Mon, 26 Feb 2024 08:02:12 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'259'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_5e02b5ba177833eaaf9f83a48ac3ce1d'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=w.u.sbm8G6gXGmA1r3o.6cdqcZy72phuOgRnJ_0Z97Q-1708934532-1.0-Abyb7yaalOWt//3G2ABD0Dot+ezq75+h/I+v/8FplPJRHf1aTDDoesCPkNhN0YgnY+seudB5JsdIF+1jqafWYy8=; path=/; expires=Mon, 26-Feb-24 08:32:12 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=1_3ztMLlhcNSyHNarKvAUnO4UtWZPVTdUogCZnpwBFY-1708934532424-0.0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'85b6aa1a49be3daa-SIN'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-02-26 17:02:12,021 INFO httpx: HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 401 Unauthorized\"\n",
      "2024-02-26 17:02:12,022 DEBUG httpcore.http11: receive_response_body.started request=<Request [b'POST']>\n",
      "2024-02-26 17:02:12,023 DEBUG httpcore.http11: receive_response_body.complete\n",
      "2024-02-26 17:02:12,024 DEBUG httpcore.http11: response_closed.started\n",
      "2024-02-26 17:02:12,025 DEBUG httpcore.http11: response_closed.complete\n",
      "2024-02-26 17:02:12,026 DEBUG openai._base_client: HTTP Request: POST https://api.openai.com/v1/completions \"401 Unauthorized\"\n",
      "2024-02-26 17:02:12,027 DEBUG openai._base_client: Encountered httpx.HTTPStatusError\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tim/miniconda3/envs/aws-lol-env/lib/python3.11/site-packages/openai/_base_client.py\", line 959, in _request\n",
      "    response.raise_for_status()\n",
      "  File \"/home/tim/miniconda3/envs/aws-lol-env/lib/python3.11/site-packages/httpx/_models.py\", line 758, in raise_for_status\n",
      "    raise HTTPStatusError(message, request=request, response=self)\n",
      "httpx.HTTPStatusError: Client error '401 Unauthorized' for url 'https://api.openai.com/v1/completions'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/401\n",
      "2024-02-26 17:02:12,030 DEBUG openai._base_client: Not retrying\n",
      "2024-02-26 17:02:12,030 DEBUG openai._base_client: Re-raising status error\n",
      "2024-02-26 17:02:12,031 WARNING root: OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: asdasdasd. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}.\n",
      "2024-02-26 17:02:12,031 WARNING root: Hit request rate limit; retrying...\n",
      "2024-02-26 17:02:14,035 DEBUG openai._base_client: Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ['You are asked to come up with a set of 100 exam questions on diverse topics related to Machine Learning at Beginner level. These question sets will be given to an language model and we will evaluate the language model for completing the instructions.\\n\\nHere are the requirements:\\n1. Try not to repeat the verb for each question to maximize diversity.\\n2. The language used for the questions also should be diverse. For example, you should combine questions with imperative instructions.\\n3. The topics in these questions should be diverse. The list should include diverse types of questions like open-ended generation, multiple-choice, true/false etc.\\n2. A language model should be able to complete the instruction. For example, do not ask the assistant to create any visual or audio output. For another example, do not ask the assistant to wake you up at 5pm or set a reminder because it cannot perform any action.\\n3. The questions should be in English.\\n4. The questions should be 1 to 2 sentences long. Either an imperative sentence or a question is permitted.\\n5. You should generate an appropriate topic related to the question. The topic should provide substantial content to make the question challenging but should ideally not exceed 100 words.\\n6. The output should be an appropriate response to the question and information provided. Make sure the output is less than 100 words.\\n7. Questions should be in the following jsonl format: {\"id\": \"seed_task_<insert number here>\", \"instruction\": \"<insert question here>\", \"info\": [{\"difficulty\": \"<insert difficulty here>\", \"topic\": \"<insert topic name here>\"}], \"output\": \"<insert response here>\"}. Each question should begin at a brand new line.\\n\\nList of 100 questions:\\n\\n\\n\\n###\\n1. Instruction: Explain the concept of underfitting in machine learning models.\\n1. Output: Underfitting occurs when a model is too simple to capture the underlying patterns in the data, resulting in poor performance both on the training and test datasets.\\n###\\n2. Instruction: Explain the concept of batch gradient descent in optimizing a neural network.\\n2. Output: Batch gradient descent computes the gradient of the loss function using the entire training dataset in each iteration, updating the model parameters accordingly to minimize the loss.\\n###\\n3. Instruction: What is the role of a loss function in training a machine learning model?\\n3. Output: The loss function quantifies the model\\'s prediction error during training, guiding the optimization process towards finding the optimal model parameters.\\n###\\n4. Instruction:'], 'max_tokens': 3072, 'n': 1, 'temperature': 0.7, 'top_p': 1.0}}\n",
      "2024-02-26 17:02:14,037 DEBUG httpcore.http11: send_request_headers.started request=<Request [b'POST']>\n",
      "2024-02-26 17:02:14,038 DEBUG httpcore.http11: send_request_headers.complete\n",
      "2024-02-26 17:02:14,039 DEBUG httpcore.http11: send_request_body.started request=<Request [b'POST']>\n",
      "2024-02-26 17:02:14,040 DEBUG httpcore.http11: send_request_body.complete\n",
      "2024-02-26 17:02:14,041 DEBUG httpcore.http11: receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-02-26 17:02:14,372 DEBUG httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Mon, 26 Feb 2024 08:02:14 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'259'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_5dd7913b3c48dee06ace33f376ae3672'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'85b6aa296b883daa-SIN'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-02-26 17:02:14,374 INFO httpx: HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 401 Unauthorized\"\n",
      "2024-02-26 17:02:14,375 DEBUG httpcore.http11: receive_response_body.started request=<Request [b'POST']>\n",
      "2024-02-26 17:02:14,376 DEBUG httpcore.http11: receive_response_body.complete\n",
      "2024-02-26 17:02:14,377 DEBUG httpcore.http11: response_closed.started\n",
      "2024-02-26 17:02:14,377 DEBUG httpcore.http11: response_closed.complete\n",
      "2024-02-26 17:02:14,378 DEBUG openai._base_client: HTTP Request: POST https://api.openai.com/v1/completions \"401 Unauthorized\"\n",
      "2024-02-26 17:02:14,379 DEBUG openai._base_client: Encountered httpx.HTTPStatusError\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tim/miniconda3/envs/aws-lol-env/lib/python3.11/site-packages/openai/_base_client.py\", line 959, in _request\n",
      "    response.raise_for_status()\n",
      "  File \"/home/tim/miniconda3/envs/aws-lol-env/lib/python3.11/site-packages/httpx/_models.py\", line 758, in raise_for_status\n",
      "    raise HTTPStatusError(message, request=request, response=self)\n",
      "httpx.HTTPStatusError: Client error '401 Unauthorized' for url 'https://api.openai.com/v1/completions'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/401\n",
      "2024-02-26 17:02:14,381 DEBUG openai._base_client: Not retrying\n",
      "2024-02-26 17:02:14,381 DEBUG openai._base_client: Re-raising status error\n",
      "2024-02-26 17:02:14,382 WARNING root: OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: asdasdasd. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}.\n",
      "2024-02-26 17:02:14,383 WARNING root: Hit request rate limit; retrying...\n",
      "2024-02-26 17:02:16,384 DEBUG openai._base_client: Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ['You are asked to come up with a set of 100 exam questions on diverse topics related to Machine Learning at Beginner level. These question sets will be given to an language model and we will evaluate the language model for completing the instructions.\\n\\nHere are the requirements:\\n1. Try not to repeat the verb for each question to maximize diversity.\\n2. The language used for the questions also should be diverse. For example, you should combine questions with imperative instructions.\\n3. The topics in these questions should be diverse. The list should include diverse types of questions like open-ended generation, multiple-choice, true/false etc.\\n2. A language model should be able to complete the instruction. For example, do not ask the assistant to create any visual or audio output. For another example, do not ask the assistant to wake you up at 5pm or set a reminder because it cannot perform any action.\\n3. The questions should be in English.\\n4. The questions should be 1 to 2 sentences long. Either an imperative sentence or a question is permitted.\\n5. You should generate an appropriate topic related to the question. The topic should provide substantial content to make the question challenging but should ideally not exceed 100 words.\\n6. The output should be an appropriate response to the question and information provided. Make sure the output is less than 100 words.\\n7. Questions should be in the following jsonl format: {\"id\": \"seed_task_<insert number here>\", \"instruction\": \"<insert question here>\", \"info\": [{\"difficulty\": \"<insert difficulty here>\", \"topic\": \"<insert topic name here>\"}], \"output\": \"<insert response here>\"}. Each question should begin at a brand new line.\\n\\nList of 100 questions:\\n\\n\\n\\n###\\n1. Instruction: Explain the concept of underfitting in machine learning models.\\n1. Output: Underfitting occurs when a model is too simple to capture the underlying patterns in the data, resulting in poor performance both on the training and test datasets.\\n###\\n2. Instruction: Explain the concept of batch gradient descent in optimizing a neural network.\\n2. Output: Batch gradient descent computes the gradient of the loss function using the entire training dataset in each iteration, updating the model parameters accordingly to minimize the loss.\\n###\\n3. Instruction: What is the role of a loss function in training a machine learning model?\\n3. Output: The loss function quantifies the model\\'s prediction error during training, guiding the optimization process towards finding the optimal model parameters.\\n###\\n4. Instruction:'], 'max_tokens': 3072, 'n': 1, 'temperature': 0.7, 'top_p': 1.0}}\n",
      "2024-02-26 17:02:16,386 DEBUG httpcore.http11: send_request_headers.started request=<Request [b'POST']>\n",
      "2024-02-26 17:02:16,387 DEBUG httpcore.http11: send_request_headers.complete\n",
      "2024-02-26 17:02:16,387 DEBUG httpcore.http11: send_request_body.started request=<Request [b'POST']>\n",
      "2024-02-26 17:02:16,388 DEBUG httpcore.http11: send_request_body.complete\n",
      "2024-02-26 17:02:16,388 DEBUG httpcore.http11: receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-02-26 17:02:16,728 DEBUG httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Mon, 26 Feb 2024 08:02:17 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'259'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_7d06e34c0e8722857a5e16e25160d2de'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'85b6aa381bb83daa-SIN'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-02-26 17:02:16,729 INFO httpx: HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 401 Unauthorized\"\n",
      "2024-02-26 17:02:16,729 DEBUG httpcore.http11: receive_response_body.started request=<Request [b'POST']>\n",
      "2024-02-26 17:02:16,729 DEBUG httpcore.http11: receive_response_body.complete\n",
      "2024-02-26 17:02:16,730 DEBUG httpcore.http11: response_closed.started\n",
      "2024-02-26 17:02:16,730 DEBUG httpcore.http11: response_closed.complete\n",
      "2024-02-26 17:02:16,730 DEBUG openai._base_client: HTTP Request: POST https://api.openai.com/v1/completions \"401 Unauthorized\"\n",
      "2024-02-26 17:02:16,731 DEBUG openai._base_client: Encountered httpx.HTTPStatusError\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tim/miniconda3/envs/aws-lol-env/lib/python3.11/site-packages/openai/_base_client.py\", line 959, in _request\n",
      "    response.raise_for_status()\n",
      "  File \"/home/tim/miniconda3/envs/aws-lol-env/lib/python3.11/site-packages/httpx/_models.py\", line 758, in raise_for_status\n",
      "    raise HTTPStatusError(message, request=request, response=self)\n",
      "httpx.HTTPStatusError: Client error '401 Unauthorized' for url 'https://api.openai.com/v1/completions'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/401\n",
      "2024-02-26 17:02:16,732 DEBUG openai._base_client: Not retrying\n",
      "2024-02-26 17:02:16,732 DEBUG openai._base_client: Re-raising status error\n",
      "2024-02-26 17:02:16,732 WARNING root: OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: asdasdasd. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}.\n",
      "2024-02-26 17:02:16,733 WARNING root: Hit request rate limit; retrying...\n",
      "prompt_batches:   0%|                                                                                                                                   | 0/5 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/projects/aws-lol-2024/notebooks/module.py:127\u001b[0m, in \u001b[0;36mSelfInstruct.openai_completion\u001b[0;34m(self, prompts, decoding_args, batch_size, max_instances, sleep_time)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;66;03m# batched completion requests\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m     completion_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch_decoding_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     choices \u001b[38;5;241m=\u001b[39m completion_batch\u001b[38;5;241m.\u001b[39mchoices\n",
      "File \u001b[0;32m~/miniconda3/envs/aws-lol-env/lib/python3.11/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/aws-lol-env/lib/python3.11/site-packages/openai/resources/completions.py:506\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, model, prompt, best_of, echo, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, seed, stop, stream, suffix, temperature, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    504\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    505\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Completion \u001b[38;5;241m|\u001b[39m Stream[Completion]:\n\u001b[0;32m--> 506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbest_of\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mecho\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mecho\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msuffix\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCompletion\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/aws-lol-env/lib/python3.11/site-packages/openai/_base_client.py:1200\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1197\u001b[0m opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1198\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1199\u001b[0m )\n\u001b[0;32m-> 1200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/aws-lol-env/lib/python3.11/site-packages/openai/_base_client.py:889\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    882\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    887\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    888\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/aws-lol-env/lib/python3.11/site-packages/openai/_base_client.py:980\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    979\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 980\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m    983\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    984\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    987\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    988\u001b[0m )\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: asdasdasd. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mself_instruct\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/aws-lol-2024/notebooks/module.py:326\u001b[0m, in \u001b[0;36mSelfInstruct.generate\u001b[0;34m(self, output_dir)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_provider \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    318\u001b[0m     decoding_args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.7\u001b[39m,\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;66;03m# \"stop\": [\"\\n20\", \"20.\", \"20.\"],\u001b[39;00m\n\u001b[1;32m    324\u001b[0m     }\n\u001b[0;32m--> 326\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopenai_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecoding_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoding_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m     request_duration \u001b[38;5;241m=\u001b[39m time() \u001b[38;5;241m-\u001b[39m request_start\n\u001b[1;32m    332\u001b[0m     process_start \u001b[38;5;241m=\u001b[39m time()\n",
      "File \u001b[0;32m~/projects/aws-lol-2024/notebooks/module.py:151\u001b[0m, in \u001b[0;36mSelfInstruct.openai_completion\u001b[0;34m(self, prompts, decoding_args, batch_size, max_instances, sleep_time)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m                 logging\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHit request rate limit; retrying...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 151\u001b[0m                 \u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43msleep_time\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Annoying rate limit on requests.\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decoding_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;66;03m# make completions a nested list, where each entry is a consecutive decoding_args.n of original entries.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     completions \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    156\u001b[0m         completions[i : i \u001b[38;5;241m+\u001b[39m decoding_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(completions), decoding_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    158\u001b[0m     ]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "self_instruct.generate(output_dir=\"./\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
