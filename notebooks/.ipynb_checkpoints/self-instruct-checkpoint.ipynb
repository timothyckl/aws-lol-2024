{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f549b54-40f7-466b-8531-960ac8a41c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.mistralai import MistralAI\n",
    "from llama_index.embeddings.mistralai import MistralAIEmbedding\n",
    "\n",
    "MISTRAL_KEY = \"N2tgkjOnSCTpY7C8QzuwWDITl0zflxhY\"\n",
    "\n",
    "llm = MistralAI(\n",
    "    api_key=MISTRAL_KEY,\n",
    "    model=\"mistral-medium\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=1024,\n",
    "    timeout=120,\n",
    "    max_retries=5,\n",
    "    safe_mode=False,\n",
    "    random_seed=None,\n",
    ")\n",
    "\n",
    "# embed_model = MistralAIEmbedding(model_name='mistral-embed', api_key=MISTRAL_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0715f21c-1bbe-4d92-bc04-58d0354a235e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction:\n",
      "I am preparing a set of exam questions about machine learning theory. \n",
      "Generate 50 questions on machine learning theory for me in this jsonl format: \n",
      "{\"instruction\": <Insert exam question>,\"context\":\"\",\"response\":\"<insert response here>} \n",
      "Each json should be begin at a brand new line.\n",
      "\n",
      "Questions:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topic = \"machine learning theory\"\n",
    "num_questions = 50\n",
    "\n",
    "prompt = f'''\\\n",
    "Instruction:\n",
    "I am preparing a set of exam questions about {topic}. \\\n",
    "\n",
    "Generate {num_questions} questions on {topic} for me in this jsonl format: \\\n",
    "\n",
    "{{\"instruction\": <Insert exam question>,\"context\":\"\",\"response\":\"<insert response here>}} \\\n",
    "\n",
    "Each json should be begin at a brand new line.\n",
    "\n",
    "Questions:\n",
    "'''\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58a205eb-50f4-45cd-9eff-cf2c16b9dbbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"instruction\": \"What is the difference between supervised and unsupervised learning?\",\"context\":\"\",\"response\":\"Supervised learning is a type of machine learning where the model is trained on labeled data, meaning that the input data is paired with the correct output. The goal is to learn a mapping from inputs to outputs that can be used to make predictions on new, unseen data. Unsupervised learning, on the other hand, is a type of machine learning where the model is trained on unlabeled data. The goal is to find patterns or structure in the data without being given any explicit guidance on what to look for.\"}\n",
      "\n",
      "{\"instruction\": \"What is overfitting in machine learning?\",\"context\":\"\",\"response\":\"Overfitting is a problem that occurs when a machine learning model is too complex and learns the noise in the training data instead of the underlying pattern. This can cause the model to perform well on the training data but poorly on new, unseen data. Overfitting can be prevented by using techniques such as regularization, cross-validation, and early stopping.\"}\n",
      "\n",
      "{\"instruction\": \"What is underfitting in machine learning?\",\"context\":\"\",\"response\":\"Underfitting is a problem that occurs when a machine learning model is too simple and is unable to capture the underlying pattern in the data. This can cause the model to perform poorly on both the training data and new, unseen data. Underfitting can be addressed by using a more complex model or by gathering more data.\"}\n",
      "\n",
      "{\"instruction\": \"What is the bias-variance tradeoff in machine learning?\",\"context\":\"\",\"response\":\"The bias-variance tradeoff is a fundamental concept in machine learning that refers to the balance between the bias and variance of a model. Bias is the error that is introduced by approximating a real-world problem with a simplified model. Variance is the error that is introduced by the model's sensitivity to the specific training data. A model with high bias and low variance will underfit the data, while a model with low bias and high variance will overfit the data. The goal is to find a model with the right balance of bias and variance that can generalize well to new, unseen data.\"}\n",
      "\n",
      "{\"instruction\": \"What is regularization in machine learning?\",\"context\":\"\",\"response\":\"Regularization is a technique used in machine learning to prevent overfitting by adding a penalty term to the loss function. This penalty term discourages the model from learning overly complex patterns in the data that may not generalize well to new, unseen data. Common regularization techniques include L1 regularization (also known as Lasso regularization) and L2 regularization (also known as Ridge regularization).\"}\n",
      "\n",
      "{\"instruction\": \"What is cross-validation in machine learning?\",\"context\":\"\",\"response\":\"Cross-validation is a technique used in machine learning to evaluate the performance of a model on new, unseen data. It involves dividing the data into multiple folds, training the model on one fold and evaluating it on the remaining folds, and then repeating this process for each fold. The average performance across all folds is then used as an estimate of the model's performance on new data.\"}\n",
      "\n",
      "{\"instruction\": \"What is the curse of dimensionality in machine learning?\",\"context\":\"\",\"response\":\"The curse of dimensionality is a problem that occurs when the number of features (or dimensions) in a dataset is very large relative to the number of samples. This can cause machine learning algorithms to become increasingly complex and prone to overfitting. It can also make it difficult to visualize and interpret the data. The curse of dimensionality can be addressed by using techniques such as dimensionality reduction and feature selection.\"}\n",
      "\n",
      "{\"instruction\": \"What is a decision tree in machine learning?\",\"context\":\"\",\"response\":\"A decision tree is a type of machine learning algorithm that is used for both classification and regression tasks. It works by recursively partitioning the data into subsets based on the values of the features. Each partition corresponds to a decision node in the tree, and the final prediction is made at the leaf nodes. Decision trees are easy to interpret and can handle both categorical and numerical data.\"}\n",
      "\n",
      "{\"instruction\": \"What is a random forest in machine learning?\",\"context\":\"\",\"response\":\"A random forest is an ensemble learning method that combines multiple decision trees to improve the performance and stability of the model. It works by training a large number of decision trees on random subsets of the data and then averaging the predictions of the trees to make the final prediction. Random forests are less prone to overfitting than individual decision trees and can handle both categorical and numerical data.\"}\n",
      "\n",
      "{\"instruction\": \"What is gradient boosting in machine\n"
     ]
    }
   ],
   "source": [
    "resp = llm.complete(prompt)\n",
    "print(resp.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
